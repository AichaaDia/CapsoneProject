{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ba9d34-e670-47d3-bc4f-9c8efca75c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# GOLD OUTPUTS\n",
    "# - Source : SILVER JOINED\n",
    "# - Outputs :\n",
    "#     1) MART (table analytique principale)\n",
    "#     2) Aggregations temporelles (daily / weekly / monthly)\n",
    "#     3) Export Parquet (analytics)\n",
    "#     4) Export CSV BI-ready\n",
    "# ==========================================================\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------\n",
    "BASE_PATH = \"/Volumes/workspace/ipsldata/capstoneipsl\"\n",
    "\n",
    "SILVER_JOINED_PATH = f\"{BASE_PATH}/data/silver/joined\"\n",
    "\n",
    "GOLD_MART_PATH = f\"{BASE_PATH}/data/gold/marts/transactions_mart\"\n",
    "GOLD_AGG_PARQUET_PATH = f\"{BASE_PATH}/data/gold/aggregates\"\n",
    "GOLD_EXPORT_CSV_PATH = f\"{BASE_PATH}/data/gold/exports\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. READ SILVER JOINED (SOURCE FOR GOLD)\n",
    "# ----------------------------------------------------------\n",
    "df_joined = spark.read.parquet(SILVER_JOINED_PATH)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. BUILD GOLD MART (TABLE ANALYTIQUE PRINCIPALE)\n",
    "# ----------------------------------------------------------\n",
    "gold_mart = df_joined.select(\n",
    "    \"transaction_id\",\n",
    "    \"client_id\",\n",
    "    \"transaction_date\",\n",
    "    \"year\",\n",
    "    \"amount\",\n",
    "    \"loan_flag\",\n",
    "    \"high_value_txn_flag\",\n",
    "    \"weekend_flag\",\n",
    "    \"balance_flag\",\n",
    "    \"client_tenure_days\"\n",
    ")\n",
    "\n",
    "gold_mart.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\") \\\n",
    "    .parquet(GOLD_MART_PATH)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. AGGREGATION FUNCTION\n",
    "# ----------------------------------------------------------\n",
    "def aggregate_transactions(df_joined):\n",
    "\n",
    "    df = (\n",
    "        df_joined\n",
    "        .withColumn(\"week\", F.weekofyear(\"transaction_date\"))\n",
    "        .withColumn(\"month\", F.month(\"transaction_date\"))\n",
    "    )\n",
    "\n",
    "    daily_agg = df.groupBy(\"transaction_date\").agg(\n",
    "        F.count(\"transaction_id\").alias(\"nb_transactions\"),\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.sum(\"high_value_txn_flag\").alias(\"high_value_count\")\n",
    "    )\n",
    "\n",
    "    weekly_agg = df.groupBy(\"year\", \"week\").agg(\n",
    "        F.count(\"transaction_id\").alias(\"nb_transactions\"),\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.sum(\"high_value_txn_flag\").alias(\"high_value_count\")\n",
    "    )\n",
    "\n",
    "    monthly_agg = df.groupBy(\"year\", \"month\").agg(\n",
    "        F.count(\"transaction_id\").alias(\"nb_transactions\"),\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.sum(\"high_value_txn_flag\").alias(\"high_value_count\")\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"daily\": daily_agg,\n",
    "        \"weekly\": weekly_agg,\n",
    "        \"monthly\": monthly_agg\n",
    "    }\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. BUILD AGGREGATES\n",
    "# ----------------------------------------------------------\n",
    "aggregates = aggregate_transactions(df_joined)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. EXPORT GOLD AGGREGATES — PARQUET (MANDATORY)\n",
    "# ----------------------------------------------------------\n",
    "for level, df in aggregates.items():\n",
    "    df.write.mode(\"overwrite\").parquet(\n",
    "        f\"{GOLD_AGG_PARQUET_PATH}/{level}\"\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 6. EXPORT GOLD AGGREGATES — CSV (BI-READY)\n",
    "# ----------------------------------------------------------\n",
    "for level, df in aggregates.items():\n",
    "    (\n",
    "        df\n",
    "        .coalesce(1)\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"header\", True)\n",
    "        .csv(f\"{GOLD_EXPORT_CSV_PATH}/{level}_csv\")\n",
    "    )\n",
    "\n",
    "print(\"✅ GOLD MART + AGGREGATES + EXPORTS GENERATED SUCCESSFULLY\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_gold_outputs.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
