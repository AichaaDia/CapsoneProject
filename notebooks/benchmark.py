# ============================================================
# Benchmark Lakehouse Pipeline 
# ============================================================

import sys, os, time, io
from datetime import datetime
from pyspark.sql import SparkSession

PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), ".."))
SRC_PATH = os.path.join(PROJECT_ROOT, "src")
if SRC_PATH not in sys.path:
    sys.path.append(SRC_PATH)

from configs.paths import SILVER_MAIN, SILVER_DELTA
from utils.file_utils import compter_parquet

REPORTS_BENCHMARKS = os.path.join(PROJECT_ROOT, "reports", "benchmarks")
os.makedirs(REPORTS_BENCHMARKS, exist_ok=True)

spark = SparkSession.builder.getOrCreate()
timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# ============================================================
# 1Ô∏è‚É£ Benchmark AVANT ‚Äî Parquet
# ============================================================
start_before = time.time()
df_before = spark.read.parquet(SILVER_MAIN)
df_before.count()
end_before = time.time()

nb_files_before, size_bytes_before = compter_parquet(SILVER_MAIN, dbutils)
size_mb_before = round(size_bytes_before / (1024*1024), 2)

old_stdout = sys.stdout
sys.stdout = buffer = io.StringIO()
df_before.explain(mode="simple")
sys.stdout = old_stdout
plan_before = buffer.getvalue()

# ============================================================
# 2Ô∏è‚É£ Benchmark APR√àS ‚Äî Delta
# ============================================================
start_after = time.time()
df_after = spark.read.format("delta").load(SILVER_DELTA)
df_after.count()
end_after = time.time()

nb_files_after, size_bytes_after = compter_parquet(SILVER_DELTA, dbutils)
size_mb_after = round(size_bytes_after / (1024*1024), 2)

old_stdout = sys.stdout
sys.stdout = buffer = io.StringIO()
df_after.explain(mode="simple")
sys.stdout = old_stdout
plan_after = buffer.getvalue()

# ============================================================
# 3Ô∏è‚É£ G√©n√©ration fichier Markdown 
# ============================================================
benchmark_file = os.path.join(REPORTS_BENCHMARKS, "benchmark_final.md")

with open(benchmark_file, "w", encoding="utf-8") as f:
    f.write("# Benchmark Lakehouse Pipeline - Version Explicative\n\n")
    f.write(f"**Date d'ex√©cution :** {timestamp}\n\n")
    
    # ---------------- AVANT ----------------
    f.write("## 1Ô∏è‚É£ Avant optimisation ‚Äî Format Parquet\n\n")
    f.write(f"- Dur√©e d'ex√©cution : {round(end_before - start_before, 2)} secondes\n")
    f.write(f"- Nombre de fichiers : {nb_files_before}\n")
    f.write(f"- Taille totale : {size_mb_before} MB\n\n")
    f.write("Cette √©tape correspond √† l'√©tat initial du pipeline. Les donn√©es sont stock√©es en format Parquet standard. "
            "Nous pouvons observer la structure actuelle et mesurer les performances de lecture avant toute optimisation. "
            "Le plan Spark ci-dessous permet de comprendre comment les transformations sont ex√©cut√©es.\n\n")
    f.write("### Plan Spark (Parquet)\n```text\n")
    f.write(plan_before + "\n```\n\n")
    
    # ---------------- APR√àS ----------------
    f.write("## 2Ô∏è‚É£ Apr√®s optimisation ‚Äî Format Delta Lake\n\n")
    f.write(f"- Dur√©e d'ex√©cution : {round(end_after - start_after, 2)} secondes\n")
    f.write(f"- Nombre de fichiers : {nb_files_after}\n")
    f.write(f"- Taille totale : {size_mb_after} MB\n\n")
    f.write("Apr√®s optimisation, les donn√©es sont stock√©es en Delta Lake. Ce format permet une meilleure gestion des transactions "
            "et souvent une am√©lioration des performances. Cette section montre comment la lecture et les transformations ont √©t√© optimis√©es. "
            "Le plan Spark ci-dessous illustre les changements dans l'ex√©cution.\n\n")
    f.write("### Plan Spark (Delta)\n```text\n")
    f.write(plan_after + "\n```\n\n")
    
    # ---------------- COMPARAISON ----------------
    f.write("## 3Ô∏è‚É£ Comparaison synth√©tique\n\n")
    f.write("| Indicateur | Avant (Parquet) | Apr√®s (Delta) | Observations |\n")
    f.write("|------------|-----------------|---------------|--------------|\n")
    
    obs_dur = "La lecture a √©t√© acc√©l√©r√©e gr√¢ce √† la structure optimis√©e et √† la gestion des transactions." \
               if (end_after - start_after) < (end_before - start_before) else "La lecture est l√©g√®rement plus lente, √† surveiller."
    f.write(f"| Dur√©e (s) | {round(end_before - start_before,2)} | {round(end_after - start_after,2)} | {obs_dur} |\n")
    
    obs_files = "Le nombre de fichiers est r√©duit, ce qui simplifie la gestion et am√©liore l'efficacit√© du pipeline." \
                if nb_files_after < nb_files_before else "Le nombre de fichiers a augment√©, v√©rifier la partition des donn√©es."
    f.write(f"| Nombre fichiers | {nb_files_before} | {nb_files_after} | {obs_files} |\n")
    
    obs_size = "La taille totale a diminu√©, indiquant une meilleure compaction et un stockage plus efficace." \
               if size_mb_after < size_mb_before else "La taille totale est l√©g√®rement sup√©rieure, √† v√©rifier pour optimiser l'espace."
    f.write(f"| Taille (MB) | {size_mb_before} | {size_mb_after} | {obs_size} |\n\n")
    
    # ---------------- ANALYSE ----------------
    f.write("## 4Ô∏è‚É£ Analyse et recommandations\n\n")
    f.write("Dans l'ensemble, l'optimisation vers Delta Lake apporte des am√©liorations en termes de performances et de gestion des fichiers. "
        "Cette synth√®se pr√©sente les r√©sultats du benchmark du pipeline Lakehouse. "
        "Elle met en √©vidence les am√©liorations obtenues apr√®s la migration vers Delta Lake, notamment sur la dur√©e d'ex√©cution et la taille des fichiers. "
        "Ces observations permettent de mieux comprendre le comportement du pipeline et servent de base pour la documentation finale du projet."
        "Autrement dit cette synth√®se fournit une vue claire des gains obtenus et des points √† surveiller pour les prochaines √©tapes.\n")

print("üéâ Benchmark complet g√©n√©r√© avec succ√®s !")
print(f"üìÑ Fichier : {benchmark_file}")
