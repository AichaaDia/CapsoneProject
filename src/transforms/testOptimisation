# ==========================================================
# verify_optim_perf_serverless.py
# V√©rification des optimisations et performances
# Compatible Serverless Databricks
# ==========================================================

from pyspark.sql import functions as F

# -----------------------------
# Chemins des donn√©es
# -----------------------------
BASE_PATH = "/Volumes/workspace/ipsldata/capstoneipsl"

SILVER_MAIN_PATH = f"{BASE_PATH}/data/silver/main_clean"
SILVER_ENRICH_PATH = f"{BASE_PATH}/data/silver/enrich_clean"
SILVER_JOINED_PATH = f"{BASE_PATH}/data/silver/joined"

print("üöÄ D√©but v√©rification optimisations et performances (Serverless)")

# ==========================================================
# Fonction utilitaire pour v√©rifier un DataFrame
# ==========================================================
def verify_df(path, name):
    print("\n============================================================")
    print(f"üîç V√©rification pour {name}")

    # 1Ô∏è‚É£ Lecture DataFrame
    try:
        df = spark.read.parquet(path)
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible de lire les donn√©es : {e}")
        return None

    # 2Ô∏è‚É£ Nombre de fichiers Parquet sur disque (approx. partitions)
    try:
        files = dbutils.fs.ls(path)
        parquet_files = [f for f in files if f.path.endswith(".parquet")]
        print(f"üìå Nombre de fichiers Parquet pour '{name}': {len(parquet_files)} (approx. partitions)")
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible de lister les fichiers : {e}")

    # 3Ô∏è‚É£ Sch√©ma et exemple de donn√©es
    print("üìå Sch√©ma des colonnes :")
    df.printSchema()
    print("üìå Exemple de donn√©es :")
    df.show(5, truncate=False)

    # 4Ô∏è‚É£ Plan physique d√©taill√©
    print("üìå Plan physique d√©taill√© (explain) :")
    try:
        df.explain(True)
        print("‚ÑπÔ∏è V√©rifier manuellement 'BroadcastHashJoin' ou shuffles dans le plan ci-dessus.")
    except Exception as e:
        print(f"‚ö†Ô∏è Explain non disponible sur Serverless: {e}")

    # 5Ô∏è‚É£ Note cache / persist
    print("‚ÑπÔ∏è Cache / persist : Sur Serverless, cache() / persist() non support√©.")
    print("   Normalement, on cacherait le DataFrame pour √©viter recalculs multiples.")

    return df

# ==========================================================
# V√©rification main_clean
# ==========================================================
df_main = verify_df(SILVER_MAIN_PATH, "main_clean")

# ==========================================================
# V√©rification enrich_clean
# ==========================================================
df_enrich = verify_df(SILVER_ENRICH_PATH, "enrich_clean")

# ==========================================================
# V√©rification joined
# ==========================================================
df_joined = verify_df(SILVER_JOINED_PATH, "joined")

print("\nüéØ V√©rification des optimisations et performances termin√©e !")
print("‚ÑπÔ∏è Pour Serverless, lire manuellement le plan `explain` pour confirmer :")
print("   - Broadcast join pour 'joined'")
print("   - Partitionnement et shuffles")
print("   - Lecture efficace en Parquet")
